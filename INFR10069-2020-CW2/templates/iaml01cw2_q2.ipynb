{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "#  Python script template for Question 2 (IAML Level 10)\n",
    "#  Note that\n",
    "#  - You should not change the filename of this file, 'iaml01cw2_q2.py', which is the file name you should use when you submit your code for this question.\n",
    "#  - You should define the functions shown below in your code.\n",
    "#  - You can define function arguments (parameters) and returns (attributes) if necessary.\n",
    "#  - In case you define helper functions, do not define them here, but put them in a separate Python module file, \"iaml01cw2_helpers.py\", and import it in this script.\n",
    "#  - For those questions requiring you to show results in tables, your code does not need to present them in tables - just showing them with print() is fine.\n",
    "#  - You do not need to include this header in your submission\n",
    "##########################################################\n",
    "\n",
    "#--- Code for loading the data set and pre-processing --->\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../helpers'))\n",
    "from iaml01cw2_helpers import *\n",
    "\n",
    "# Load the data:\n",
    "dataPath = os.path.join(os.getcwd(),'../data')\n",
    "Xtrn, Ytrn, Xtst, Ytst = load_FashionMNIST(dataPath)\n",
    "Xtrn_orig = Xtrn.copy\n",
    "Xtst_orig = Xtst.copy\n",
    "Xtrn = Xtrn/255\n",
    "Xtst = Xtst/255\n",
    "\n",
    "Xmean = Xtrn.mean(0)\n",
    "Xtrn_nm = Xtrn - Xmean\n",
    "Xtst_nm = Xtst - Xmean\n",
    "#<----\n",
    "\n",
    "# Q2.1\n",
    "def iaml01cw2_q2_1():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pandas as pd\n",
    "    \n",
    "    print(\"Starting Q2.1...\\n\")\n",
    "    \n",
    "    #Initialize and train our LogisticRegression model\n",
    "    lr = LogisticRegression().fit(Xtrn_nm,Ytrn)\n",
    "    pred = lr.predict(Xtst_nm)\n",
    "    \n",
    "    #Print the confusion matrix for prediction frequencies\n",
    "    print(\"FREQUENCY CONFUSION MATRIX:\\n\")\n",
    "    cm = pd.crosstab(pred,Ytst,rownames=[\"Actual\"],colnames=[\"Predicted\"])\n",
    "    print(cm.round(3))\n",
    "    \n",
    "    #Print the confusion matrix for prediction percentages\n",
    "    print(\"\\n\\nPERCENTAGE CONFUSION MATRIX:\\n\")\n",
    "    cm2 = cm/np.sum(cm,axis=1)\n",
    "    print((cm2*100).round(1))\n",
    "    \n",
    "    #Print the total classification accuracy\n",
    "    print(\"\\n\\nClassification accuracy = \" + str((((cm*np.identity(10)).sum().sum()/cm.sum().sum())*100).round(3)) + \"%\")\n",
    "    \n",
    "#\n",
    "# iaml01cw2_q2_1()   # comment this out when you run the function\n",
    "\n",
    "# Q2.2\n",
    "def iaml01cw2_q2_2():\n",
    "    from sklearn.svm import SVC\n",
    "    import pandas as pd\n",
    "    \n",
    "    print(\"Starting Q2.2...\\n\")\n",
    "    \n",
    "    #Initialize and train our SVM model\n",
    "    svc = SVC(kernel = \"rbf\", C=1.0, gamma = \"auto\").fit(Xtrn_nm,Ytrn)\n",
    "    pred = svc.predict(Xtst_nm)\n",
    "    \n",
    "    #Print the confusion matrix for prediction frequencies\n",
    "    print(\"FREQUENCY CONFUSION MATRIX:\\n\")\n",
    "    cm = pd.crosstab(pred,Ytst,rownames=[\"Actual\"],colnames=[\"Predicted\"])\n",
    "    print(cm.round(3))\n",
    "    \n",
    "    #Print the confusion matrix for prediction percentages\n",
    "    print(\"\\n\\nPERCENTAGE CONFUSION MATRIX:\\n\")\n",
    "    cm2 = cm/np.sum(cm,axis=1)\n",
    "    print((cm2*100).round(1))\n",
    "    \n",
    "    #Print the total classification accuracy\n",
    "    print(\"\\n\\nClassification accuracy = \" + str((((cm2*np.identity(10)).sum().sum()/10)*100).round(3)) + \"%\")\n",
    "    \n",
    "#\n",
    "# iaml01cw2_q2_2()   # comment this out when you run the function\n",
    "\n",
    "# Q2.3\n",
    "def iaml01cw2_q2_3():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.decomposition import PCA\n",
    "    import statistics as stats\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from matplotlib import ticker\n",
    "\n",
    "    print(\"Starting Q2.3...\\n\")\n",
    "    \n",
    "    #Initialize and train our LogisticRegrssion model\n",
    "    lr = LogisticRegression().fit(Xtrn_nm[0:100,:],Ytrn[0:100])\n",
    "    \n",
    "    #Initialize and fit our PCA model\n",
    "    pca = PCA(n_components=2).fit(Xtrn_nm[0:100,:])\n",
    "    newXtrn_nm = pca.transform(Xtrn_nm[0:100,:])\n",
    "    lr1 = LogisticRegression().fit(newXtrn_nm[0:100,:],Ytrn[0:100])\n",
    "    \n",
    "    pc0 = pca.components_[0]\n",
    "    pc1 = pca.components_[1]\n",
    "    \n",
    "    pc0Stdev = stats.stdev(pc0)\n",
    "    pc1Stdev = stats.stdev(pc1)\n",
    "    \n",
    "    #x = np.linspace(-5*pc0Stdev,5*pc0Stdev,784)\n",
    "    #y = np.linspace(-5*pc1Stdev,5*pc1Stdev,784)\n",
    "    #X, Y = np.meshgrid(x,y)\n",
    "    \n",
    "    xx, yy = np.mgrid[-5*pc0Stdev:5*pc0Stdev:10*pc0Stdev/784, -5*pc1Stdev:5*pc1Stdev:10*pc1Stdev/784]\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    probs = lr1.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "    \n",
    "    #Z = np.dot(x,pca.components_.T)\n",
    "    #print(Z)\n",
    "    #print(pca.components_.shape)\n",
    "\n",
    "    #inputs = np.empty((2,784))\n",
    "    #inputs[0,:] = x\n",
    "    #inputs[1,:] = y\n",
    "    \n",
    "    #z = np.matmul(pca.components_.T,inputs)\n",
    "    \n",
    "    colors = plt.cm.get_cmap(\"coolwarm\")(np.linspace(0,1,10))\n",
    "    newCmap = ListedColormap(colors)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    cs = ax.contourf(xx,yy,probs,cmap=newCmap)\n",
    "        \n",
    "    cbar = fig.colorbar(cs)\n",
    "    tick_locator = ticker.MaxNLocator(nbins=12)\n",
    "    cbar.locator = tick_locator\n",
    "    cbar.update_ticks()\n",
    "    cbar.ax.set_yticklabels(np.linspace(0,9,10))\n",
    "    cbar.set_label(\"\\nClass\")\n",
    "    \n",
    "    plt.xlim(-5*pc0Stdev,5*pc0Stdev)\n",
    "    plt.ylim(-5*pc1Stdev,5*pc1Stdev)\n",
    "    plt.title(\"A graph to show the 2D decision regions for our\\ntrained logistic regression classifier\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    \n",
    "    newX = [-5*pc0Stdev,-2.5*pc0Stdev,0,2.5*pc0Stdev,5*pc0Stdev]\n",
    "    plt.xticks(newX,[\"-5$\\sigma_1$\",\"-2.5$\\sigma_1$\",\"0$\\sigma_1$\",\"2.5$\\sigma_1$\",\"5$\\sigma_1$\"])\n",
    "    newY = [-5*pc1Stdev,-2.5*pc1Stdev,0,2.5*pc1Stdev,5*pc1Stdev]\n",
    "    plt.yticks(newY,[\"-5$\\sigma_2$\",\"-2.5$\\sigma_2$\",\"0$\\sigma_2$\",\"2.5$\\sigma_2$\",\"5$\\sigma_2$\"])\n",
    "    \n",
    "    plt.axhline(0, color='black')\n",
    "    plt.axvline(0, color='black')\n",
    "    plt.show()\n",
    "#\n",
    "# iaml01cw2_q2_3()   # comment this out when you run the function\n",
    "\n",
    "# Q2.4\n",
    "#def iaml01cw2_q2_4():\n",
    "#\n",
    "# iaml01cw2_q2_4()   # comment this out when you run the function\n",
    "\n",
    "# Q2.5\n",
    "def iaml01cw2_q2_5():\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import math\n",
    "        \n",
    "    print(\"Starting Q2.5...\\n\")    \n",
    "    \n",
    "    #Initialize numpy matrices to store our sliced dataset\n",
    "    Xsmall = np.empty((10000,784))\n",
    "    Ysmall = np.empty(10000)\n",
    "    \n",
    "    #Numpy array to store the amount of samples for each class\n",
    "    classAmounts = np.zeros(10)\n",
    "    \n",
    "    #Populate the Xsmall and Ysmall numpy matrices\n",
    "    index = 0\n",
    "    for row in range(Xtrn_nm.shape[0]):\n",
    "        \n",
    "        label = Ytrn[row]\n",
    "        \n",
    "        #Checks if a class has 1000 samples yet\n",
    "        if classAmounts[label] < 1000:\n",
    "            Xsmall[index,:] = Xtrn_nm[row,:]\n",
    "            Ysmall[index] = label\n",
    "            classAmounts[label] += 1\n",
    "            index += 1\n",
    "        \n",
    "        #If our dataset has 10000 samples we break the loop\n",
    "        if classAmounts.sum() == 10000:\n",
    "            break\n",
    "    \n",
    "    #Create 10 equally log spaced values for C\n",
    "    C = np.logspace(-2,3,10,endpoint=True)\n",
    "    print(C)\n",
    "    #Initialize numpy array to store the accuracies\n",
    "    accuracies = np.empty(10)\n",
    "    print(math.log(C[6],10))\n",
    "    \n",
    "    #Iterate through each value of C\n",
    "    for i in range(C.size):\n",
    "        c = C[i]\n",
    "        print(c)\n",
    "        \n",
    "        #Initialize our SVM model\n",
    "        svc = SVC(kernel = \"rbf\", C=c, gamma = \"auto\")\n",
    "        \n",
    "        #Get the cross-validated classification accuracy\n",
    "        score = cross_val_score(svc,Xsmall,Ysmall,cv=3)\n",
    "        accuracies[i] = np.sum(score)/len(score)\n",
    "        print(accuracies[i])\n",
    "    \n",
    "    print(accuracies)\n",
    "    print()\n",
    "    #Plot the accuracies against the values of C\n",
    "    plt.scatter(C,accuracies,c=\"black\")\n",
    "    plt.plot(C,accuracies,c=\"black\")\n",
    "    \n",
    "    #Highlight the point of maximum accuracy\n",
    "    maxIndex = np.where(accuracies == max(accuracies))\n",
    "    plt.scatter(C[maxIndex],accuracies[maxIndex],c=\"red\",label=\"Highest mean accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    \n",
    "    #Plot features for further readability\n",
    "    plt.grid(True)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"C\")\n",
    "    plt.ylabel(\"Mean cross-validated classification accuracy\")\n",
    "    plt.title(\"A graph to show the relationship between the regularisation\\nparameter C and the mean cross-validated\\nclassification accuracy\")\n",
    "        \n",
    "    \n",
    "#\n",
    "# iaml01cw2_q2_5()   # comment this out when you run the function\n",
    "\n",
    "# Q2.6 \n",
    "def iaml01cw2_q2_6():\n",
    "    from sklearn.svm import SVC\n",
    "    import math\n",
    "    \n",
    "    print(\"Starting Q2.6...\\n\")\n",
    "    \n",
    "    #Retrieve the optimal value of C\n",
    "    C = np.logspace(-2,3,10,endpoint=True)\n",
    "    c = math.log(C[6],10)\n",
    "    \n",
    "    #Initialize and train our SVM model\n",
    "    svc = SVC(kernel=\"rbf\",C=c,gamma=\"auto\").fit(Xtrn_nm,Ytrn)\n",
    "    \n",
    "    #Print the training and testing accuracies of this model\n",
    "    print(\"Training accuracy = \" + str(round(svc.score(Xtrn_nm,Ytrn)*100,3)) + \"%\")\n",
    "    print(\"Testing accuracy = \" + str(round(svc.score(Xtst_nm,Ytst)*100,3)) + \"%\")\n",
    "    \n",
    "#\n",
    "# iaml01cw2_q2_6()   # comment this out when you run the function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q2.2...\n",
      "\n",
      "FREQUENCY CONFUSION MATRIX:\n",
      "\n",
      "Predicted    0    1    2    3    4    5    6    7    8    9\n",
      "Actual                                                     \n",
      "0          845    4   15   32    1    0  185    0    3    0\n",
      "1            2  951    2    6    0    0    1    0    1    0\n",
      "2            8    7  748   12   98    0  122    0    8    0\n",
      "3           51   31   11  881   36    1   39    0    5    0\n",
      "4            4    5  137   26  775    0   95    0    2    0\n",
      "5            4    0    0    0    0  914    0   34    4   22\n",
      "6           72    1   79   40   86    0  533    0   13    0\n",
      "7            0    0    0    0    0   57    0  925    4   47\n",
      "8           14    1    8    3    4    2   25    0  959    1\n",
      "9            0    0    0    0    0   26    0   41    1  930\n",
      "\n",
      "\n",
      "PERCENTAGE CONFUSION MATRIX:\n",
      "\n",
      "Predicted     0     1     2     3     4     5     6     7     8     9\n",
      "Actual                                                               \n",
      "0          77.9   0.4   1.5   3.0   0.1   0.0  22.5   0.0   0.3   0.0\n",
      "1           0.2  98.8   0.2   0.6   0.0   0.0   0.1   0.0   0.1   0.0\n",
      "2           0.7   0.7  74.6   1.1   9.4   0.0  14.8   0.0   0.8   0.0\n",
      "3           4.7   3.2   1.1  83.5   3.4   0.1   4.7   0.0   0.5   0.0\n",
      "4           0.4   0.5  13.7   2.5  74.2   0.0  11.5   0.0   0.2   0.0\n",
      "5           0.4   0.0   0.0   0.0   0.0  93.5   0.0   3.3   0.4   2.2\n",
      "6           6.6   0.1   7.9   3.8   8.2   0.0  64.7   0.0   1.3   0.0\n",
      "7           0.0   0.0   0.0   0.0   0.0   5.8   0.0  89.5   0.4   4.7\n",
      "8           1.3   0.1   0.8   0.3   0.4   0.2   3.0   0.0  94.3   0.1\n",
      "9           0.0   0.0   0.0   0.0   0.0   2.7   0.0   4.0   0.1  93.2\n",
      "\n",
      "\n",
      "Classification accuracy = 84.412%\n"
     ]
    }
   ],
   "source": [
    "iaml01cw2_q2_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.logspace(-2,3,10,endpoint=True)\n",
    "print(math.log(C[6],10) == math.log(4/3,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
