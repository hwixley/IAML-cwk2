{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "#  Python script template for Question 1 (IAML Level 10)\n",
    "#  Note that\n",
    "#  - You should not change the filename of this file, 'iaml01cw2_q1.py', which is the file name you should use when you submit your code for this question.\n",
    "#  - You should define the functions shown below in your code.\n",
    "#  - You can define function arguments (parameters) and returns (attributes) if necessary.\n",
    "#  - In case you define helper functions, do not define them here, but put them in a separate Python module file, \"iaml01cw2_my_helpers.py\", and import it in this script.\n",
    "#  - For those questions requiring you to show results in tables, your code does not need to present them in tables - just showing them with print() is fine.\n",
    "#  - You do not need to include this header in your submission\n",
    "##########################################################\n",
    "\n",
    "#--- Code for loading the data set and pre-processing --->\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../helpers'))\n",
    "from iaml01cw2_helpers import *\n",
    "\n",
    "# Load the data:\n",
    "dataPath = os.path.join(os.getcwd(),'../data')\n",
    "Xtrn, Ytrn, Xtst, Ytst = load_FashionMNIST(dataPath)\n",
    "Xtrn_orig = Xtrn.copy\n",
    "Xtst_orig = Xtst.copy\n",
    "Xtrn = Xtrn/255.0\n",
    "Xtst = Xtst/255.0\n",
    "\n",
    "Xmean = Xtrn.mean(0)\n",
    "Xtrn_nm = Xtrn - Xmean\n",
    "Xtst_nm = Xtst - Xmean\n",
    "#<----\n",
    "\n",
    "# Q1.1\n",
    "def iaml01cw2_q1_1():\n",
    "    \n",
    "    #Print elements of first training sample\n",
    "    print(\"First 4 elements of the first training sample in Xtrn_nm:\")\n",
    "    print(Xtrn_nm[0,0:4])\n",
    "    \n",
    "    #Print elements of last training sample\n",
    "    print(\"\\nFirst 4 elements of the last training sample in Xtrn_nm:\")\n",
    "    print(Xtrn_nm[-1,0:4])\n",
    "    \n",
    "#\n",
    "# iaml01cw2_q1_1()   # comment this out when you run the function\n",
    "\n",
    "# Q1.2\n",
    "def iaml01cw2_q1_2():\n",
    "    \n",
    "    print(\"Starting Q1.2...\\n\")\n",
    "    \n",
    "    # Array of classes\n",
    "    classes = np.unique(Ytrn)\n",
    "    \n",
    "    # Initialisation of variables\n",
    "    classSamples = []\n",
    "    means = []\n",
    "    closest = []\n",
    "    furthest = []\n",
    "    classMeans = np.zeros((10,784))\n",
    "    \n",
    "    # Initialise empty nested arrays\n",
    "    for c in classes:\n",
    "        classSamples.append([])\n",
    "        closest.append([])\n",
    "        furthest.append([])\n",
    "    \n",
    "    # Add all the indexes of samples for a given classs in the classSamples list\n",
    "    for row in range(Ytrn.size): \n",
    "        classSamples[Ytrn[row]].append(row)\n",
    "    \n",
    "    # Iterates over all classes (to calculate means, closest and furthest samples)\n",
    "    for c in range(10):\n",
    "        #Represents the relevant samples for the given class c\n",
    "        samples = classSamples[c]\n",
    "        \n",
    "        #Calculate the mean samples for each class\n",
    "        for index in samples:\n",
    "            classMeans[c] += Xtrn[index,:]\n",
    "            \n",
    "        classMeans[c] = classMeans[c]/len(samples)\n",
    "        meanC = classMeans[c].reshape(28,28)\n",
    "        means.append(meanC)\n",
    "        \n",
    "        #Calculate closest samples variables\n",
    "        close1 = -1\n",
    "        closeDist1 = 10000\n",
    "        close2 = -1\n",
    "        closeDist2 = 10000\n",
    "        #Calculate furthest samples variables\n",
    "        far1 = -1\n",
    "        farDist1 = 0\n",
    "        far2 = -1\n",
    "        farDist2 = 0\n",
    "        \n",
    "        #Iterate through the samples of the given class to find the closest & furthest samples\n",
    "        for index in samples:\n",
    "            dist = sum((classMeans[c]-Xtrn[index,:])**2)\n",
    "            \n",
    "            if dist < closeDist1:\n",
    "                close1 = index\n",
    "                closeDist1 = dist\n",
    "            elif dist < closeDist2:\n",
    "                close2 = index\n",
    "                closeDist2 = dist\n",
    "                \n",
    "            if dist > farDist1:\n",
    "                far1 = index\n",
    "                farDist1 = dist\n",
    "            elif dist > farDist2:\n",
    "                far2 = index\n",
    "                farDist2 = dist\n",
    "        \n",
    "        #Store the closest and furthest samples\n",
    "        closest[c].append(close1)\n",
    "        closest[c].append(close2)\n",
    "        furthest[c].append(far1)\n",
    "        furthest[c].append(far2)\n",
    "    \n",
    "    #Create a subplot to show the relevant samples\n",
    "    fig, axs = plt.subplots(10,5,figsize=(16,16))\n",
    "    fig.tight_layout(h_pad=2.5)\n",
    "    for i in range(10):\n",
    "        #Mean\n",
    "        axs[i,0].imshow(means[i], cmap=\"gray_r\")\n",
    "        axs[i,0].set_ylabel(\"Class \" + str(i) + \"\\n\",fontsize=20)\n",
    "        axs[i,0].set_xticklabels([])\n",
    "        axs[i,0].set_yticklabels([])\n",
    "        \n",
    "        for n in range(1,3):\n",
    "            #Closest\n",
    "            axs[i,n].imshow(Xtrn[closest[i][n-1],:].reshape(28,28), cmap=\"gray_r\")\n",
    "            axs[i,n].set_title(\"Sample \" + str(closest[i][n-1]),fontsize=18)\n",
    "            axs[i,n].set_xticklabels([])\n",
    "            axs[i,n].set_yticklabels([])\n",
    "            \n",
    "            #Furthest\n",
    "            axs[i,n+2].imshow(Xtrn[furthest[i][-n+2],:].reshape(28,28), cmap=\"gray_r\")\n",
    "            axs[i,n+2].set_title(\"Sample \" + str(furthest[i][-n+2]),fontsize=18)\n",
    "            axs[i,n+2].set_xticklabels([])\n",
    "            axs[i,n+2].set_yticklabels([])\n",
    "    \n",
    "    #Add appropriate axis labels to the subplot\n",
    "    axs[9,0].set_xlabel(\"\\nMean sample\",fontsize=20)\n",
    "    axs[9,1].set_xlabel(\"\\nClosest sample\\nto mean\",fontsize=20)\n",
    "    axs[9,2].set_xlabel(\"\\n2nd closest sample\\nto mean\",fontsize=20)\n",
    "    axs[9,3].set_xlabel(\"\\n2nd furthest sample\\nfrom mean\",fontsize=20)\n",
    "    axs[9,4].set_xlabel(\"\\nFurthest sample\\nfrom mean\",fontsize=20)\n",
    "            \n",
    "                \n",
    "#\n",
    "# iaml01cw2_q1_2()   # comment this out when you run the function\n",
    "\n",
    "# Q1.3\n",
    "def iaml01cw2_q1_3():\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    print(\"Starting Q1.3...\\n\")\n",
    "    \n",
    "    #Apply PCA to our normalized training data\n",
    "    pca = PCA().fit(Xtrn_nm)\n",
    "    \n",
    "    #Print the explained variance for the first 5 PCs\n",
    "    print(\"The explained variances for the first 5 principal components:\")\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(\"PC \" + str(i+1) + \" = \" + str(pca.explained_variance_[i]))\n",
    "    \n",
    "    \n",
    "#\n",
    "# iaml01cw2_q1_3()   # comment this out when you run the function\n",
    "\n",
    "\n",
    "# Q1.4\n",
    "def iaml01cw2_q1_4():\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    \n",
    "    print(\"Starting Q1.4...\\n\")\n",
    "    \n",
    "    #Initialize arrays to store number of attributes and cumVar\n",
    "    y = np.empty(784)\n",
    "    x = np.arange(1,785)\n",
    "    \n",
    "    #Iterate through all different possible number of PCA components\n",
    "    for n in range(784):\n",
    "        pca = PCA(n_components=n+1).fit(Xtrn_nm)\n",
    "        y[n] = pca.explained_variance_ratio_.sum()\n",
    "    \n",
    "    #Plot the data appropriately\n",
    "    plt.plot(x,y)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"K\",fontsize=16)\n",
    "    plt.ylabel(\"Cumulative explained variance ratio\",fontsize=16)\n",
    "    plt.title(\"A graph to show the relationship between the cumulative explained variance\\nratio and the number of principal components (K) for 'Xtrn_nm'\",fontsize=18)\n",
    "\n",
    "#\n",
    "# iaml01cw2_q1_4()   # comment this out when you run the function\n",
    "\n",
    "\n",
    "# Q1.5\n",
    "def iaml01cw2_q1_5():\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    print(\"Starting Q1.5...\\n\")\n",
    "    \n",
    "    #Initialize PCA model\n",
    "    pca = PCA().fit(Xtrn_nm)\n",
    "    \n",
    "    #Plot the first 10 principal components in a 2-by-5 grid\n",
    "    fig, axs = plt.subplots(2,5,figsize=(15,15))\n",
    "    index = 0\n",
    "    for r in range(2):\n",
    "        for c in range(5):\n",
    "            axs[r,c].imshow(pca.components_[index].reshape(28,28))\n",
    "            axs[r,c].set_title(\"PC \" + str(index+1),fontsize=18)\n",
    "            index += 1\n",
    "\n",
    "#\n",
    "# iaml01cw2_q1_5()   # comment this out when you run the function\n",
    "\n",
    "\n",
    "# Q1.6\n",
    "def iaml01cw2_q1_6():\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from math import sqrt\n",
    "    \n",
    "    print(\"Starting Q1.6...\\n\")\n",
    "    \n",
    "    #Set up arrays to store relevant data\n",
    "    classes = np.unique(Ytrn)\n",
    "    K = [5,20,50,200]\n",
    "    orig_classSamples = np.empty((10,784))\n",
    "    \n",
    "    # Get indexes of the first samples for each class\n",
    "    for c in classes:\n",
    "        for s in range(Ytrn.size):\n",
    "            if Ytrn[s] == c:\n",
    "                orig_classSamples[c,:] = Xtrn_nm[s,:]\n",
    "                break\n",
    "    \n",
    "    #Numpy matrix to store all the RMSE scores\n",
    "    rmse = np.empty((10,4))\n",
    "    \n",
    "    #Iterate through the different values of K\n",
    "    for i in range(4):\n",
    "        \n",
    "        #Initialize PCA model\n",
    "        pca = PCA(n_components=K[i]).fit(Xtrn_nm)\n",
    "        \n",
    "        #Iterate through the different classes\n",
    "        for s in range(10):\n",
    "            \n",
    "            #Original X vector\n",
    "            X = orig_classSamples[s,:]\n",
    "            \n",
    "            #Transformed X vector\n",
    "            newX = pca.transform(X.reshape(1,-1))\n",
    "            \n",
    "            #Reconstructed X vector\n",
    "            inverseX = pca.inverse_transform(newX.reshape(-1))\n",
    "            \n",
    "            #Output RMSE to rmse numpy matrix\n",
    "            rmse[s,i] = sqrt(mean_squared_error(X,inverseX))\n",
    "    \n",
    "    #Print the rounded RMSE matrix\n",
    "    print(np.round(rmse,3))\n",
    "            \n",
    "            \n",
    "#\n",
    "# iaml01cw2_q1_6()   # comment this out when you run the function\n",
    "\n",
    "\n",
    "# Q1.7\n",
    "def iaml01cw2_q1_7():\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    \n",
    "    print(\"Starting Q1.7...\\n\")\n",
    "    \n",
    "    #Set up arrays to store relevant data\n",
    "    classes = np.unique(Ytrn)\n",
    "    K = [5,20,50,200]\n",
    "    orig_classSamples = np.empty((10,784))\n",
    "    \n",
    "    # Get the first samples for each class\n",
    "    for c in classes:\n",
    "        for s in range(Ytrn.size):\n",
    "            if Ytrn[s] == c:\n",
    "                orig_classSamples[c,:] = Xtrn_nm[s,:]\n",
    "                break\n",
    "    \n",
    "    #Variables to store the inversely transformed samples\n",
    "    index1 = 0\n",
    "    new_classSamples = np.empty((40,784))\n",
    "    \n",
    "    #Iterate through the different values of K\n",
    "    for i in range(4):\n",
    "        \n",
    "        #Initialize PCA model\n",
    "        pca = PCA(n_components=K[i]).fit(Xtrn_nm)\n",
    "        \n",
    "        #Iterate through the different classes\n",
    "        for s in range(10):\n",
    "            \n",
    "            #Original X vector\n",
    "            X = orig_classSamples[s,:]\n",
    "            \n",
    "            #Transformed X vector\n",
    "            newX = pca.transform(X.reshape(1,-1))\n",
    "            \n",
    "            #Reconstructed X vector\n",
    "            inverseX = pca.inverse_transform(newX.reshape(-1))\n",
    "            \n",
    "            #Store the reconstructed X vector\n",
    "            new_classSamples[index1,:] = inverseX + Xmean\n",
    "            index1 += 1\n",
    "    \n",
    "    #Put all of these images into a subplot\n",
    "    fig, axs = plt.subplots(10,4,figsize=(18,18))\n",
    "    index = 0\n",
    "    for k in range(4):\n",
    "        for c in range(10):\n",
    "            #Plot the class labels on the y axis\n",
    "            if k == 0:\n",
    "                axs[c,k].set_ylabel(\"Class \" + str(c),fontsize=20)\n",
    "            \n",
    "            #Plot the image and set the tick labels\n",
    "            axs[c,k].imshow(new_classSamples[index,:].reshape(28,28))\n",
    "            axs[c,k].set_xticklabels([])\n",
    "            axs[c,k].set_yticklabels([])\n",
    "            index += 1\n",
    "    \n",
    "    #Plot the K labels on the x axis\n",
    "    axs[9,0].set_xlabel(\"K = 5\",fontsize=20)\n",
    "    axs[9,1].set_xlabel(\"K = 20\",fontsize=20)\n",
    "    axs[9,2].set_xlabel(\"K = 50\",fontsize=20)\n",
    "    axs[9,3].set_xlabel(\"K = 200\",fontsize=20)\n",
    "    plt.suptitle(\"A grid to show the images of the reconstructed class samples\\nfor varying amounts of dimension reductions (K)\", fontsize=24)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#\n",
    "# iaml01cw2_q1_7()   # comment this out when you run the function\n",
    "\n",
    "\n",
    "# Q1.8\n",
    "def iaml01cw2_q1_8():\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    print(\"Starting Q1.8...\\n\")\n",
    "    \n",
    "    #Set up PCA model\n",
    "    pca = PCA(n_components=2).fit(Xtrn_nm)\n",
    "    \n",
    "    #Get 2D version of Xtrn_nm\n",
    "    newXtrn = pca.transform(Xtrn_nm)\n",
    "    \n",
    "    #Initialize plot variables\n",
    "    x = newXtrn[:,0]\n",
    "    y = newXtrn[:,1]\n",
    "    \n",
    "    #Plot scatter\n",
    "    sc = plt.scatter(x,y,c=Ytrn,cmap=\"coolwarm\",alpha =0.4)\n",
    "    \n",
    "    #Implement a colorbar\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"\\nClass number\", fontsize=15)\n",
    "    \n",
    "    #Plot features for further readability\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"PC1\",fontsize=16)\n",
    "    plt.ylabel(\"PC2\",fontsize=16)\n",
    "    plt.title(\"A 2D-PCA plane to show the relationship between\\nthe different classes in our dataset 'Xtrn_nm'\",fontsize=18)\n",
    "\n",
    "#\n",
    "# iaml01cw2_q1_8()   # comment this out when you run the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q1.4...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f6a3d9772ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miaml01cw2_q1_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-236ab9990fe7>\u001b[0m in \u001b[0;36miaml01cw2_q1_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m#Iterate through all different possible number of PCA components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrn_nm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[0;32m~/packages/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    493\u001b[0m                                      \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                                      \u001b[0mflip_sign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                                      random_state=random_state)\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     Q = randomized_range_finder(M, n_random, n_iter,\n\u001b[0;32m--> 326\u001b[0;31m                                 power_iteration_normalizer, random_state)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# project M to the (k + p) dimensional space using the basis vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'QR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iaml01cw2_q1_4()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
